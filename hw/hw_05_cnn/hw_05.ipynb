{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "hw_05.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdBwH2zZFEor",
        "colab_type": "text"
      },
      "source": [
        "# Shaikat Islam\n",
        "\n",
        "## HW05: CIFAR-10 Using CNNs \n",
        "\n",
        "### Source: https://machinelearningmastery.com/object-recognition-convolutional-neural-networks-keras-deep-learning-library/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6PAmLAFFEos",
        "colab_type": "text"
      },
      "source": [
        "### 1.1: Load the CIFAR-10 Dataset in Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTOkN-lsFEot",
        "colab_type": "code",
        "outputId": "ae68d6fd-50e7-4da3-8203-9f8712bacfd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.constraints import maxnorm\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# loading data\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# small sample of 9 images\n",
        "for i in range(0, 9):\n",
        "    pyplot.subplot(330 + 1 + i)\n",
        "    pyplot.imshow(x_train[i])\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU4AAAD7CAYAAAAFI30bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb827pu6FEow",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 Normalizing Input Values and Data Transformation\n",
        "\n",
        "Here, we normalize the data by dividng each of the pixel RGB values by 255, as the range of the values is from 0-255. The data values are cast to floating point values in order to divide."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxP6POhtFEox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalizing inputs\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKXSs7kZFEoz",
        "colab_type": "text"
      },
      "source": [
        "Use one-hot encoding to convert the outputs to a data format more suited for ML tasks -- here we are converting the data to a 10x10 binary matrix. \n",
        "\n",
        "One-hot encoding converts categorical data to numerical data in the form of a binary matrix. This differs from integer encoding, which requires an ordinal relationship within data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYh_RxBOFEo0",
        "colab_type": "code",
        "outputId": "4eb9be1a-12a4-457c-dd61-8ef270864f3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWtVfw1VGpSd",
        "colab_type": "text"
      },
      "source": [
        "### 1.3 Baseline Convolutional Neural Network\n",
        "\n",
        "The following baseline CNN uses a convolutional input layer, in which neurons receive input from a size 3x3 feature map (of which there are 32). Furthermore, a rectifier activation function is used (ReLU), which is the activation function for this model. The weight constraint of max norm is set to 3, which is the absolute upper bound on the size of the weight vector for every neuron. The dropout value is set to 20%, which is used to regularize the CNN by \"dropping\" both hidden and visible neurons. Another convolutional input layer is added to the model (the same as the first), and the max pooling layer (used to down-sample the input) is set at a size of 2x2. After the feature map is pooled, it is flattened to a column-like shape to be used as an input layer for the fully-connected layer composed of 512 hidden  neurons (using a rectifier activation function), and a dropout of 50%, followed by another fully connected layer with 10 hidden neurons and a soft-max activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy4xCWDhJaNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating the model\n",
        "# linear stack of layers \n",
        "model = Sequential()\n",
        "# convolutional input layer, in which neurons receive input from a size 3x3 feature map (of which there are 32)\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
        "# dropout value is set to 20%, which is used to regularize the CNN by \"dropping\" both hidden and visible neurons\n",
        "model.add(Dropout(0.2))\n",
        "# convolutional input layer, in which neurons receive input from a size 3x3 feature map (of which there are 32)\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
        "# pool feature map to 2x2\n",
        "model.add(MaxPooling2D())\n",
        "# flattened to a column-like shape to be used as an input layer \n",
        "model.add(Flatten())\n",
        "# fully-connected layer composed of 512 hidden neurons (using a rectifier activation function)\n",
        "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "# dropout of 50%\n",
        "model.add(Dropout(0.5))\n",
        "# fully connected layer with 10 hidden neurons and a soft-max activation function\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ei-pgKvKEEu",
        "colab_type": "text"
      },
      "source": [
        "### 1.4 Compiling the Model\n",
        "The optimizer being used for this model is a logarithmic loss function with the stochastic gradient descent optimization algorithm with an learning rate of .01, 25 epochs, and a large momentum of 0.9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UP3LXH9yKSWm",
        "colab_type": "code",
        "outputId": "628d3d8d-b3e0-4c7a-ab93-cff117ece986",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "epochs = 25\n",
        "lrate = 0.01\n",
        "decay = lrate/epochs\n",
        "# stochastic gradient descent optimizer\n",
        "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 512)               4194816   \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 4,210,090\n",
            "Trainable params: 4,210,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7FPqQ4_K__w",
        "colab_type": "text"
      },
      "source": [
        "### 1.5 Training the Model\n",
        "Here we train the model with 25 epochs and a batch size of 32. It should be noted that the number of iterations is usually greater for this application, but is reduced for sake of time. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egfxhoJSLNFG",
        "colab_type": "code",
        "outputId": "05ab51c0-2f5d-4d98-d203-5b49527e2716",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Training the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=32)\n",
        "# Accuracy of model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/25\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "50000/50000 [==============================] - 26s 526us/step - loss: 1.6851 - acc: 0.3895 - val_loss: 1.4259 - val_acc: 0.4815\n",
            "Epoch 2/25\n",
            "50000/50000 [==============================] - 19s 374us/step - loss: 1.3162 - acc: 0.5269 - val_loss: 1.1668 - val_acc: 0.5875\n",
            "Epoch 3/25\n",
            "50000/50000 [==============================] - 19s 373us/step - loss: 1.1471 - acc: 0.5919 - val_loss: 1.0692 - val_acc: 0.6219\n",
            "Epoch 4/25\n",
            "50000/50000 [==============================] - 19s 374us/step - loss: 1.0229 - acc: 0.6365 - val_loss: 1.0177 - val_acc: 0.6392\n",
            "Epoch 5/25\n",
            "50000/50000 [==============================] - 19s 381us/step - loss: 0.9246 - acc: 0.6704 - val_loss: 0.9661 - val_acc: 0.6579\n",
            "Epoch 6/25\n",
            "50000/50000 [==============================] - 19s 373us/step - loss: 0.8422 - acc: 0.7009 - val_loss: 0.9574 - val_acc: 0.6646\n",
            "Epoch 7/25\n",
            "50000/50000 [==============================] - 19s 373us/step - loss: 0.7686 - acc: 0.7278 - val_loss: 0.9355 - val_acc: 0.6739\n",
            "Epoch 8/25\n",
            "50000/50000 [==============================] - 19s 377us/step - loss: 0.7087 - acc: 0.7495 - val_loss: 0.9219 - val_acc: 0.6820\n",
            "Epoch 9/25\n",
            "50000/50000 [==============================] - 19s 373us/step - loss: 0.6513 - acc: 0.7702 - val_loss: 0.9064 - val_acc: 0.6906\n",
            "Epoch 10/25\n",
            "50000/50000 [==============================] - 19s 373us/step - loss: 0.5955 - acc: 0.7884 - val_loss: 0.9168 - val_acc: 0.6887\n",
            "Epoch 11/25\n",
            "50000/50000 [==============================] - 19s 373us/step - loss: 0.5534 - acc: 0.8044 - val_loss: 0.9253 - val_acc: 0.6928\n",
            "Epoch 12/25\n",
            "50000/50000 [==============================] - 19s 370us/step - loss: 0.5158 - acc: 0.8168 - val_loss: 0.9219 - val_acc: 0.6964\n",
            "Epoch 13/25\n",
            "50000/50000 [==============================] - 19s 372us/step - loss: 0.4790 - acc: 0.8296 - val_loss: 0.9319 - val_acc: 0.6961\n",
            "Epoch 14/25\n",
            "50000/50000 [==============================] - 19s 374us/step - loss: 0.4447 - acc: 0.8431 - val_loss: 0.9372 - val_acc: 0.6956\n",
            "Epoch 15/25\n",
            "50000/50000 [==============================] - 19s 372us/step - loss: 0.4163 - acc: 0.8533 - val_loss: 0.9649 - val_acc: 0.6966\n",
            "Epoch 16/25\n",
            "50000/50000 [==============================] - 19s 371us/step - loss: 0.3899 - acc: 0.8612 - val_loss: 0.9557 - val_acc: 0.7004\n",
            "Epoch 17/25\n",
            "50000/50000 [==============================] - 19s 372us/step - loss: 0.3651 - acc: 0.8707 - val_loss: 0.9721 - val_acc: 0.6996\n",
            "Epoch 18/25\n",
            "50000/50000 [==============================] - 19s 371us/step - loss: 0.3439 - acc: 0.8792 - val_loss: 0.9943 - val_acc: 0.7030\n",
            "Epoch 19/25\n",
            "50000/50000 [==============================] - 19s 370us/step - loss: 0.3213 - acc: 0.8886 - val_loss: 0.9947 - val_acc: 0.7026\n",
            "Epoch 20/25\n",
            "50000/50000 [==============================] - 19s 370us/step - loss: 0.3052 - acc: 0.8933 - val_loss: 1.0088 - val_acc: 0.7049\n",
            "Epoch 21/25\n",
            "50000/50000 [==============================] - 19s 372us/step - loss: 0.2905 - acc: 0.8986 - val_loss: 1.0277 - val_acc: 0.7051\n",
            "Epoch 22/25\n",
            "50000/50000 [==============================] - 19s 380us/step - loss: 0.2768 - acc: 0.9035 - val_loss: 1.0313 - val_acc: 0.6996\n",
            "Epoch 23/25\n",
            "50000/50000 [==============================] - 19s 372us/step - loss: 0.2627 - acc: 0.9076 - val_loss: 1.0483 - val_acc: 0.7044\n",
            "Epoch 24/25\n",
            "50000/50000 [==============================] - 19s 371us/step - loss: 0.2526 - acc: 0.9101 - val_loss: 1.0548 - val_acc: 0.7040\n",
            "Epoch 25/25\n",
            "50000/50000 [==============================] - 19s 375us/step - loss: 0.2396 - acc: 0.9153 - val_loss: 1.0694 - val_acc: 0.7033\n",
            "Accuracy: 70.33%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOuMTMB0Ox8x",
        "colab_type": "text"
      },
      "source": [
        "### 1.6 Improving on the Baseline\n",
        "\n",
        "The previous model had an accuracy of 70.33%, but the model can be tweaked to do better. \n",
        "\n",
        "The following section builds upon the last model, by introducing more convolutional layers and more feature maps (with the same pattern of convolutional, dropout, convolutional, and max pooling layers). \n",
        "\n",
        "The pattern is the same as the first model, except it is repeated three times, each with a 32x32, 64x64, and 128x128 sized feature map, respectively. The final dense layer is also larger, with 512 units, instead of 10 in the previous model. The number of epochs is the same, but the batch size has doubled to 64, instead of 32, as in the previous model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiHFRwEYP5Kx",
        "colab_type": "code",
        "outputId": "355bb4c9-aea7-48d5-ac05-2d47b3e6c018",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# load data, normalize by dividing rgb vals by 255, and one-hot encode\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "\n",
        "# same pattern as previous model, except repeated 3 times with larger feature maps\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "# larger dense layer (512 instead of 10)\n",
        "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# number of epochs and learning rate stays the same, but batch size increases to 64\n",
        "epochs = 25\n",
        "lrate = 0.01\n",
        "decay = lrate/epochs\n",
        "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# training the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=64)\n",
        "# accuracy of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_49 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "dropout_49 (Dropout)         (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_50 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_51 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "dropout_50 (Dropout)         (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_52 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_53 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "dropout_51 (Dropout)         (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_54 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_27 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_52 (Dropout)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dropout_53 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_54 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 2,915,114\n",
            "Trainable params: 2,915,114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/25\n",
            "50000/50000 [==============================] - 23s 461us/step - loss: 1.9416 - acc: 0.2790 - val_loss: 1.7282 - val_acc: 0.3659\n",
            "Epoch 2/25\n",
            "50000/50000 [==============================] - 22s 437us/step - loss: 1.5370 - acc: 0.4394 - val_loss: 1.4062 - val_acc: 0.4966\n",
            "Epoch 3/25\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 1.3495 - acc: 0.5086 - val_loss: 1.2234 - val_acc: 0.5563\n",
            "Epoch 4/25\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 1.2267 - acc: 0.5546 - val_loss: 1.2037 - val_acc: 0.5680\n",
            "Epoch 5/25\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 1.1190 - acc: 0.5978 - val_loss: 1.0923 - val_acc: 0.6135\n",
            "Epoch 6/25\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 1.0393 - acc: 0.6290 - val_loss: 0.9900 - val_acc: 0.6463\n",
            "Epoch 7/25\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 0.9550 - acc: 0.6585 - val_loss: 0.9117 - val_acc: 0.6793\n",
            "Epoch 8/25\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.8941 - acc: 0.6819 - val_loss: 0.9144 - val_acc: 0.6783\n",
            "Epoch 9/25\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.8415 - acc: 0.7006 - val_loss: 0.8570 - val_acc: 0.6977\n",
            "Epoch 10/25\n",
            "50000/50000 [==============================] - 22s 437us/step - loss: 0.7861 - acc: 0.7201 - val_loss: 0.8314 - val_acc: 0.7084\n",
            "Epoch 11/25\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 0.7527 - acc: 0.7338 - val_loss: 0.7933 - val_acc: 0.7217\n",
            "Epoch 12/25\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 0.7143 - acc: 0.7474 - val_loss: 0.7626 - val_acc: 0.7322\n",
            "Epoch 13/25\n",
            "50000/50000 [==============================] - 22s 437us/step - loss: 0.6778 - acc: 0.7605 - val_loss: 0.7264 - val_acc: 0.7418\n",
            "Epoch 14/25\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.6516 - acc: 0.7705 - val_loss: 0.7210 - val_acc: 0.7481\n",
            "Epoch 15/25\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.6220 - acc: 0.7785 - val_loss: 0.7123 - val_acc: 0.7524\n",
            "Epoch 16/25\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.5976 - acc: 0.7886 - val_loss: 0.6983 - val_acc: 0.7566\n",
            "Epoch 17/25\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.5759 - acc: 0.7967 - val_loss: 0.6952 - val_acc: 0.7581\n",
            "Epoch 18/25\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.5580 - acc: 0.8030 - val_loss: 0.6782 - val_acc: 0.7647\n",
            "Epoch 19/25\n",
            "50000/50000 [==============================] - 22s 437us/step - loss: 0.5375 - acc: 0.8107 - val_loss: 0.6676 - val_acc: 0.7704\n",
            "Epoch 20/25\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.5189 - acc: 0.8171 - val_loss: 0.6675 - val_acc: 0.7743\n",
            "Epoch 21/25\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.5021 - acc: 0.8220 - val_loss: 0.6586 - val_acc: 0.7774\n",
            "Epoch 22/25\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.4848 - acc: 0.8268 - val_loss: 0.6550 - val_acc: 0.7775\n",
            "Epoch 23/25\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.4719 - acc: 0.8305 - val_loss: 0.6570 - val_acc: 0.7786\n",
            "Epoch 24/25\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.4536 - acc: 0.8381 - val_loss: 0.6522 - val_acc: 0.7846\n",
            "Epoch 25/25\n",
            "50000/50000 [==============================] - 22s 437us/step - loss: 0.4440 - acc: 0.8430 - val_loss: 0.6354 - val_acc: 0.7837\n",
            "Accuracy: 78.37%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F12qTmy_Sk9w",
        "colab_type": "text"
      },
      "source": [
        "### 2.1 Training for More Epochs\n",
        "\n",
        "The previous model used deeper network topology than the baseline, but had an increase in accuracy of 8%, with a final accuracy if 78.37%. In this section, we explore three extensions on the previous model: training for more epochs, augmenting data, and a deeper network topology (these suggestions were taken from the tutorial)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXGFShCDWVOK",
        "colab_type": "code",
        "outputId": "e2f2fcfe-1170-4465-aa74-7691445ed2c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# load data, normalize by dividing rgb vals by 255, and one-hot encode\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "\n",
        "# same pattern as previous model, except repeated 3 times with larger feature maps\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "# larger dense layer (512 instead of 10)\n",
        "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# number of epochs quadruples and learning rate stays the same, but batch size increases to 64\n",
        "epochs = 100\n",
        "lrate = 0.01\n",
        "decay = lrate/epochs\n",
        "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# training the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=64)\n",
        "# accuracy of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "acc.append(scores)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_55 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "dropout_55 (Dropout)         (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_56 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_57 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "dropout_56 (Dropout)         (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_58 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_29 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_59 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "dropout_57 (Dropout)         (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_60 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_30 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_58 (Dropout)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dropout_59 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_60 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 2,915,114\n",
            "Trainable params: 2,915,114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "50000/50000 [==============================] - 23s 462us/step - loss: 1.9305 - acc: 0.2848 - val_loss: 1.6245 - val_acc: 0.3946\n",
            "Epoch 2/100\n",
            "50000/50000 [==============================] - 22s 437us/step - loss: 1.4943 - acc: 0.4548 - val_loss: 1.3614 - val_acc: 0.5200\n",
            "Epoch 3/100\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 1.3047 - acc: 0.5284 - val_loss: 1.2022 - val_acc: 0.5640\n",
            "Epoch 4/100\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 1.1628 - acc: 0.5853 - val_loss: 1.0531 - val_acc: 0.6267\n",
            "Epoch 5/100\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 1.0345 - acc: 0.6310 - val_loss: 0.9592 - val_acc: 0.6619\n",
            "Epoch 6/100\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 0.9318 - acc: 0.6696 - val_loss: 0.9029 - val_acc: 0.6798\n",
            "Epoch 7/100\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 0.8469 - acc: 0.7004 - val_loss: 0.8305 - val_acc: 0.7114\n",
            "Epoch 8/100\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 0.7721 - acc: 0.7269 - val_loss: 0.7567 - val_acc: 0.7357\n",
            "Epoch 9/100\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 0.7095 - acc: 0.7484 - val_loss: 0.7196 - val_acc: 0.7485\n",
            "Epoch 10/100\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 0.6585 - acc: 0.7675 - val_loss: 0.6857 - val_acc: 0.7622\n",
            "Epoch 11/100\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 0.6077 - acc: 0.7850 - val_loss: 0.6739 - val_acc: 0.7686\n",
            "Epoch 12/100\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 0.5692 - acc: 0.7966 - val_loss: 0.6709 - val_acc: 0.7678\n",
            "Epoch 13/100\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 0.5222 - acc: 0.8141 - val_loss: 0.6581 - val_acc: 0.7784\n",
            "Epoch 14/100\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 0.4980 - acc: 0.8216 - val_loss: 0.6547 - val_acc: 0.7776\n",
            "Epoch 15/100\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 0.4626 - acc: 0.8354 - val_loss: 0.6454 - val_acc: 0.7801\n",
            "Epoch 16/100\n",
            "50000/50000 [==============================] - 22s 439us/step - loss: 0.4332 - acc: 0.8433 - val_loss: 0.6351 - val_acc: 0.7876\n",
            "Epoch 17/100\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 0.4022 - acc: 0.8559 - val_loss: 0.6282 - val_acc: 0.7890\n",
            "Epoch 18/100\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 0.3781 - acc: 0.8658 - val_loss: 0.6277 - val_acc: 0.7938\n",
            "Epoch 19/100\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 0.3482 - acc: 0.8751 - val_loss: 0.6317 - val_acc: 0.7952\n",
            "Epoch 20/100\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 0.3223 - acc: 0.8845 - val_loss: 0.6298 - val_acc: 0.7999\n",
            "Epoch 21/100\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 0.3141 - acc: 0.8891 - val_loss: 0.6284 - val_acc: 0.7958\n",
            "Epoch 22/100\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.2911 - acc: 0.8950 - val_loss: 0.6621 - val_acc: 0.7906\n",
            "Epoch 23/100\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 0.2753 - acc: 0.9021 - val_loss: 0.6489 - val_acc: 0.7950\n",
            "Epoch 24/100\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 0.2585 - acc: 0.9066 - val_loss: 0.6622 - val_acc: 0.7981\n",
            "Epoch 25/100\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 0.2463 - acc: 0.9117 - val_loss: 0.6546 - val_acc: 0.7979\n",
            "Epoch 26/100\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.2238 - acc: 0.9184 - val_loss: 0.6937 - val_acc: 0.7962\n",
            "Epoch 27/100\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 0.2098 - acc: 0.9251 - val_loss: 0.6592 - val_acc: 0.8072\n",
            "Epoch 28/100\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 0.1991 - acc: 0.9278 - val_loss: 0.6803 - val_acc: 0.8058\n",
            "Epoch 29/100\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 0.1946 - acc: 0.9299 - val_loss: 0.6663 - val_acc: 0.8036\n",
            "Epoch 30/100\n",
            "50000/50000 [==============================] - 22s 437us/step - loss: 0.1796 - acc: 0.9353 - val_loss: 0.6969 - val_acc: 0.8019\n",
            "Epoch 31/100\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 0.1720 - acc: 0.9386 - val_loss: 0.7071 - val_acc: 0.8032\n",
            "Epoch 32/100\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 0.1595 - acc: 0.9427 - val_loss: 0.7148 - val_acc: 0.8081\n",
            "Epoch 33/100\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 0.1545 - acc: 0.9455 - val_loss: 0.7198 - val_acc: 0.8079\n",
            "Epoch 34/100\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 0.1448 - acc: 0.9490 - val_loss: 0.7455 - val_acc: 0.8057\n",
            "Epoch 35/100\n",
            "50000/50000 [==============================] - 22s 432us/step - loss: 0.1420 - acc: 0.9491 - val_loss: 0.7291 - val_acc: 0.8047\n",
            "Epoch 36/100\n",
            "50000/50000 [==============================] - 22s 432us/step - loss: 0.1358 - acc: 0.9518 - val_loss: 0.7234 - val_acc: 0.8053\n",
            "Epoch 37/100\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 0.1289 - acc: 0.9544 - val_loss: 0.7407 - val_acc: 0.8071\n",
            "Epoch 38/100\n",
            "50000/50000 [==============================] - 22s 432us/step - loss: 0.1271 - acc: 0.9542 - val_loss: 0.7467 - val_acc: 0.8125\n",
            "Epoch 39/100\n",
            "50000/50000 [==============================] - 22s 430us/step - loss: 0.1193 - acc: 0.9580 - val_loss: 0.7225 - val_acc: 0.8117\n",
            "Epoch 40/100\n",
            "50000/50000 [==============================] - 22s 430us/step - loss: 0.1129 - acc: 0.9603 - val_loss: 0.7424 - val_acc: 0.8090\n",
            "Epoch 41/100\n",
            "50000/50000 [==============================] - 22s 430us/step - loss: 0.1110 - acc: 0.9604 - val_loss: 0.7367 - val_acc: 0.8096\n",
            "Epoch 42/100\n",
            "50000/50000 [==============================] - 22s 432us/step - loss: 0.1068 - acc: 0.9628 - val_loss: 0.7477 - val_acc: 0.8069\n",
            "Epoch 43/100\n",
            "50000/50000 [==============================] - 22s 430us/step - loss: 0.1024 - acc: 0.9647 - val_loss: 0.7904 - val_acc: 0.8106\n",
            "Epoch 44/100\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 0.0969 - acc: 0.9655 - val_loss: 0.7701 - val_acc: 0.8120\n",
            "Epoch 45/100\n",
            "50000/50000 [==============================] - 22s 432us/step - loss: 0.0946 - acc: 0.9660 - val_loss: 0.7918 - val_acc: 0.8078\n",
            "Epoch 46/100\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 0.0854 - acc: 0.9705 - val_loss: 0.7877 - val_acc: 0.8142\n",
            "Epoch 47/100\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 0.0908 - acc: 0.9684 - val_loss: 0.7737 - val_acc: 0.8122\n",
            "Epoch 48/100\n",
            "50000/50000 [==============================] - 22s 431us/step - loss: 0.0844 - acc: 0.9704 - val_loss: 0.7810 - val_acc: 0.8139\n",
            "Epoch 49/100\n",
            "50000/50000 [==============================] - 22s 432us/step - loss: 0.0831 - acc: 0.9708 - val_loss: 0.8191 - val_acc: 0.8125\n",
            "Epoch 50/100\n",
            "50000/50000 [==============================] - 22s 432us/step - loss: 0.0816 - acc: 0.9719 - val_loss: 0.7993 - val_acc: 0.8119\n",
            "Epoch 51/100\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 0.0777 - acc: 0.9732 - val_loss: 0.7862 - val_acc: 0.8138\n",
            "Epoch 52/100\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 0.0740 - acc: 0.9736 - val_loss: 0.7919 - val_acc: 0.8133\n",
            "Epoch 53/100\n",
            "50000/50000 [==============================] - 22s 437us/step - loss: 0.0720 - acc: 0.9749 - val_loss: 0.8151 - val_acc: 0.8140\n",
            "Epoch 54/100\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.0698 - acc: 0.9759 - val_loss: 0.7980 - val_acc: 0.8133\n",
            "Epoch 55/100\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.0688 - acc: 0.9766 - val_loss: 0.8023 - val_acc: 0.8151\n",
            "Epoch 56/100\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.0666 - acc: 0.9768 - val_loss: 0.8289 - val_acc: 0.8132\n",
            "Epoch 57/100\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 0.0671 - acc: 0.9772 - val_loss: 0.8250 - val_acc: 0.8128\n",
            "Epoch 58/100\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.0638 - acc: 0.9779 - val_loss: 0.8192 - val_acc: 0.8160\n",
            "Epoch 59/100\n",
            "50000/50000 [==============================] - 22s 438us/step - loss: 0.0638 - acc: 0.9782 - val_loss: 0.8313 - val_acc: 0.8137\n",
            "Epoch 60/100\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 0.0583 - acc: 0.9797 - val_loss: 0.8318 - val_acc: 0.8135\n",
            "Epoch 61/100\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 0.0616 - acc: 0.9788 - val_loss: 0.8296 - val_acc: 0.8148\n",
            "Epoch 62/100\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 0.0582 - acc: 0.9806 - val_loss: 0.8440 - val_acc: 0.8140\n",
            "Epoch 63/100\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.0554 - acc: 0.9807 - val_loss: 0.8218 - val_acc: 0.8135\n",
            "Epoch 64/100\n",
            "50000/50000 [==============================] - 22s 432us/step - loss: 0.0534 - acc: 0.9819 - val_loss: 0.8553 - val_acc: 0.8147\n",
            "Epoch 65/100\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 0.0527 - acc: 0.9825 - val_loss: 0.8391 - val_acc: 0.8151\n",
            "Epoch 66/100\n",
            "50000/50000 [==============================] - 22s 437us/step - loss: 0.0534 - acc: 0.9809 - val_loss: 0.8349 - val_acc: 0.8153\n",
            "Epoch 67/100\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 0.0482 - acc: 0.9833 - val_loss: 0.8478 - val_acc: 0.8176\n",
            "Epoch 68/100\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 0.0499 - acc: 0.9830 - val_loss: 0.8506 - val_acc: 0.8137\n",
            "Epoch 69/100\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.0475 - acc: 0.9837 - val_loss: 0.8813 - val_acc: 0.8184\n",
            "Epoch 70/100\n",
            "50000/50000 [==============================] - 22s 437us/step - loss: 0.0479 - acc: 0.9833 - val_loss: 0.8540 - val_acc: 0.8195\n",
            "Epoch 71/100\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 0.0467 - acc: 0.9837 - val_loss: 0.8804 - val_acc: 0.8168\n",
            "Epoch 72/100\n",
            "50000/50000 [==============================] - 22s 437us/step - loss: 0.0450 - acc: 0.9841 - val_loss: 0.8662 - val_acc: 0.8187\n",
            "Epoch 73/100\n",
            "50000/50000 [==============================] - 22s 440us/step - loss: 0.0445 - acc: 0.9847 - val_loss: 0.8569 - val_acc: 0.8185\n",
            "Epoch 74/100\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 0.0447 - acc: 0.9848 - val_loss: 0.8656 - val_acc: 0.8171\n",
            "Epoch 75/100\n",
            "50000/50000 [==============================] - 22s 438us/step - loss: 0.0438 - acc: 0.9855 - val_loss: 0.9077 - val_acc: 0.8115\n",
            "Epoch 76/100\n",
            "50000/50000 [==============================] - 22s 437us/step - loss: 0.0431 - acc: 0.9853 - val_loss: 0.8662 - val_acc: 0.8182\n",
            "Epoch 77/100\n",
            "50000/50000 [==============================] - 22s 437us/step - loss: 0.0413 - acc: 0.9858 - val_loss: 0.8753 - val_acc: 0.8165\n",
            "Epoch 78/100\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.0422 - acc: 0.9856 - val_loss: 0.8880 - val_acc: 0.8151\n",
            "Epoch 79/100\n",
            "50000/50000 [==============================] - 22s 444us/step - loss: 0.0422 - acc: 0.9858 - val_loss: 0.8575 - val_acc: 0.8152\n",
            "Epoch 80/100\n",
            "50000/50000 [==============================] - 22s 439us/step - loss: 0.0388 - acc: 0.9870 - val_loss: 0.9004 - val_acc: 0.8176\n",
            "Epoch 81/100\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.0400 - acc: 0.9859 - val_loss: 0.8856 - val_acc: 0.8183\n",
            "Epoch 82/100\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.0388 - acc: 0.9866 - val_loss: 0.8859 - val_acc: 0.8146\n",
            "Epoch 83/100\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.0374 - acc: 0.9873 - val_loss: 0.8871 - val_acc: 0.8171\n",
            "Epoch 84/100\n",
            "50000/50000 [==============================] - 22s 437us/step - loss: 0.0396 - acc: 0.9863 - val_loss: 0.8946 - val_acc: 0.8169\n",
            "Epoch 85/100\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.0396 - acc: 0.9863 - val_loss: 0.8758 - val_acc: 0.8168\n",
            "Epoch 86/100\n",
            "50000/50000 [==============================] - 22s 437us/step - loss: 0.0385 - acc: 0.9865 - val_loss: 0.8993 - val_acc: 0.8181\n",
            "Epoch 87/100\n",
            "50000/50000 [==============================] - 22s 439us/step - loss: 0.0373 - acc: 0.9873 - val_loss: 0.8826 - val_acc: 0.8175\n",
            "Epoch 88/100\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.0373 - acc: 0.9875 - val_loss: 0.8588 - val_acc: 0.8163\n",
            "Epoch 89/100\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.0324 - acc: 0.9890 - val_loss: 0.9062 - val_acc: 0.8135\n",
            "Epoch 90/100\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 0.0336 - acc: 0.9885 - val_loss: 0.8978 - val_acc: 0.8179\n",
            "Epoch 91/100\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 0.0329 - acc: 0.9884 - val_loss: 0.8939 - val_acc: 0.8164\n",
            "Epoch 92/100\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 0.0337 - acc: 0.9881 - val_loss: 0.9081 - val_acc: 0.8185\n",
            "Epoch 93/100\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 0.0323 - acc: 0.9885 - val_loss: 0.9164 - val_acc: 0.8152\n",
            "Epoch 94/100\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 0.0323 - acc: 0.9891 - val_loss: 0.8943 - val_acc: 0.8181\n",
            "Epoch 95/100\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 0.0320 - acc: 0.9888 - val_loss: 0.8971 - val_acc: 0.8177\n",
            "Epoch 96/100\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 0.0318 - acc: 0.9893 - val_loss: 0.9257 - val_acc: 0.8156\n",
            "Epoch 97/100\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 0.0305 - acc: 0.9890 - val_loss: 0.9059 - val_acc: 0.8195\n",
            "Epoch 98/100\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 0.0310 - acc: 0.9900 - val_loss: 0.9242 - val_acc: 0.8185\n",
            "Epoch 99/100\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 0.0319 - acc: 0.9894 - val_loss: 0.9149 - val_acc: 0.8152\n",
            "Epoch 100/100\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 0.0290 - acc: 0.9902 - val_loss: 0.9329 - val_acc: 0.8202\n",
            "Accuracy: 82.02%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwoh21TNhEUH",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.1 Classifier Accuracy over Training Period (Epochs = 100)\n",
        "\n",
        "Quadrupling the number of epochs resulted in an increased accuracy of 4%, from 78.37% to 82.02%. Too many epochs can cause the model to overfit on the training data, which is why early stopping might be advisable in this case (as can be seen by the following plot, accuracy flatlines at about 80% near 30-100 epochs.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuT0prGyhPP8",
        "colab_type": "code",
        "outputId": "7aa0e93f-7092-4863-a8a8-87ec5432cc15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "# It was easier to do this than re-run my model and wait another 45 mins \n",
        "val_acc = [0.3946, 0.5200, 0.5640, 0.6267, 0.6619, 0.6798, 0.7114, 0.7357 ,0.7622 ,0.7686 ,0.7678 ,0.7784 ,0.7776 ,0.7801 ,0.7876 ,0.7890 ,0.7938 ,0.7952 ,0.7999 ,0.7958 ,0.7906 ,0.7950 ,0.7981 ,0.7979, 0.7962, 0.8072, 0.8058, 0.8036, 0.8019, 0.8032, 0.8081, 0.8079, 0.8057, 0.8047, 0.8053, 0.8071, 0.8125, 0.8117, 0.8090, 0.8096, 0.8069, 0.8106, 0.8120, 0.8078, 0.8142, 0.8122, 0.8139, 0.8125, 0.8119, 0.8138, 0.8133, 0.8140, 0.8133, 0.8151, 0.8132, 0.8128, 0.8160, 0.8137, 0.8135, 0.8148, 0.8140, 0.8135, 0.8147, 0.8151, 0.8153, 0.8176, 0.8137, 0.8184, 0.8195, 0.8168, 0.8187, 0.8185, 0.8171, 0.8115, 0.8182, 0.8165, 0.8151, 0.8152, 0.8176, 0.8183, 0.8146, 0.8171, 0.8169, 0.8168, 0.8181, 0.8175, 0.8163, 0.8135, 0.8179, 0.8164, 0.8185, 0.8152, 0.8181, 0.8177, 0.8156, 0.8195, 0.8185, 0.8152, 0.8202]\n",
        "num_iterations = []\n",
        "for i in range(1,100):\n",
        "   num_iterations.append(i)\n",
        "\n",
        "# plotting accuracy vs. number of epochs\n",
        "pyplot.xlabel(\"Number of Epochs\")\n",
        "pyplot.ylabel(\"Accuracy\")\n",
        "pyplot.plot(num_iterations, val_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f51150145c0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqwTJSGFnODs",
        "colab_type": "text"
      },
      "source": [
        "### 2.2 Data Augmentation \n",
        "In the following code segment, we augment the data using the ImageDataGenerator class in Keras, which transforms the actual training images by rotation, flips, normalization, and other methods. The model used is the same as used in 1.6.\n",
        "\n",
        "Here, the rotation range is within 20 degrees, the shift in width is set to 0.1 of the image size, as is the shift in height, and the images are also flipped.\n",
        "\n",
        "Source Used for Data Augmentation:\n",
        "https://appliedmachinelearning.blog/2018/03/24/achieving-90-accuracy-in-object-recognition-task-on-cifar-10-dataset-with-keras-convolutional-neural-networks/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_5ZOQgNoZio",
        "colab_type": "code",
        "outputId": "405213d4-6b8b-4d8e-bd9f-9df746f5b365",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# load data, normalize by dividing rgb vals by 255, and one-hot encode\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "\n",
        "# same pattern as previous model, except repeated 3 times with larger feature maps\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "# larger dense layer (512 instead of 10)\n",
        "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# number of epochs and learning rate stays the same, but batch size increases to 64\n",
        "epochs = 25\n",
        "lrate = 0.01\n",
        "decay = lrate/epochs\n",
        "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# augmenting the data\n",
        "data_augmentation = ImageDataGenerator(rotation_range=20, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True,)\n",
        "data_augmentation.fit(X_train)\n",
        " \n",
        "# training the model\n",
        "history = model.fit_generator(data_augmentation.flow(X_train, y_train, batch_size=64),\\\n",
        "                    steps_per_epoch=x_train.shape[0] // 64,epochs=25,\\\n",
        "                    verbose=1,validation_data=(x_test,y_test))\n",
        "\n",
        "# accuracy of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_115 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "dropout_115 (Dropout)        (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_116 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_58 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_117 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "dropout_116 (Dropout)        (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_118 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_59 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_119 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "dropout_117 (Dropout)        (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_120 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_60 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_22 (Flatten)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_118 (Dropout)        (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_61 (Dense)             (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dropout_119 (Dropout)        (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_120 (Dropout)        (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 2,915,114\n",
            "Trainable params: 2,915,114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "781/781 [==============================] - 43s 55ms/step - loss: 2.0104 - acc: 0.2545 - val_loss: 1.7994 - val_acc: 0.3264\n",
            "Epoch 2/25\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 1.6532 - acc: 0.3962 - val_loss: 1.5040 - val_acc: 0.4343\n",
            "Epoch 3/25\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 1.4929 - acc: 0.4562 - val_loss: 1.3494 - val_acc: 0.5071\n",
            "Epoch 4/25\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 1.3966 - acc: 0.4924 - val_loss: 1.2771 - val_acc: 0.5234\n",
            "Epoch 5/25\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 1.3151 - acc: 0.5233 - val_loss: 1.1797 - val_acc: 0.5743\n",
            "Epoch 6/25\n",
            "781/781 [==============================] - 41s 53ms/step - loss: 1.2550 - acc: 0.5472 - val_loss: 1.1080 - val_acc: 0.5987\n",
            "Epoch 7/25\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 1.2019 - acc: 0.5691 - val_loss: 1.1668 - val_acc: 0.5793\n",
            "Epoch 8/25\n",
            "781/781 [==============================] - 42s 54ms/step - loss: 1.1558 - acc: 0.5864 - val_loss: 1.0109 - val_acc: 0.6392\n",
            "Epoch 9/25\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 1.1090 - acc: 0.6036 - val_loss: 0.9875 - val_acc: 0.6468\n",
            "Epoch 10/25\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 1.0786 - acc: 0.6139 - val_loss: 0.9537 - val_acc: 0.6649\n",
            "Epoch 11/25\n",
            "781/781 [==============================] - 41s 52ms/step - loss: 1.0413 - acc: 0.6270 - val_loss: 0.9106 - val_acc: 0.6802\n",
            "Epoch 12/25\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 1.0063 - acc: 0.6399 - val_loss: 0.8879 - val_acc: 0.6852\n",
            "Epoch 13/25\n",
            "781/781 [==============================] - 42s 54ms/step - loss: 0.9768 - acc: 0.6518 - val_loss: 0.8844 - val_acc: 0.6900\n",
            "Epoch 14/25\n",
            "781/781 [==============================] - 42s 54ms/step - loss: 0.9558 - acc: 0.6588 - val_loss: 0.8225 - val_acc: 0.7127\n",
            "Epoch 15/25\n",
            "781/781 [==============================] - 42s 54ms/step - loss: 0.9334 - acc: 0.6681 - val_loss: 0.8446 - val_acc: 0.7051\n",
            "Epoch 16/25\n",
            "781/781 [==============================] - 42s 53ms/step - loss: 0.9173 - acc: 0.6751 - val_loss: 0.8039 - val_acc: 0.7176\n",
            "Epoch 17/25\n",
            "781/781 [==============================] - 41s 52ms/step - loss: 0.9036 - acc: 0.6812 - val_loss: 0.7815 - val_acc: 0.7257\n",
            "Epoch 18/25\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.8845 - acc: 0.6855 - val_loss: 0.7631 - val_acc: 0.7295\n",
            "Epoch 19/25\n",
            "781/781 [==============================] - 42s 54ms/step - loss: 0.8635 - acc: 0.6953 - val_loss: 0.7706 - val_acc: 0.7289\n",
            "Epoch 20/25\n",
            "781/781 [==============================] - 43s 55ms/step - loss: 0.8557 - acc: 0.6957 - val_loss: 0.7353 - val_acc: 0.7406\n",
            "Epoch 21/25\n",
            "781/781 [==============================] - 42s 54ms/step - loss: 0.8358 - acc: 0.7051 - val_loss: 0.7302 - val_acc: 0.7451\n",
            "Epoch 22/25\n",
            "781/781 [==============================] - 42s 54ms/step - loss: 0.8228 - acc: 0.7073 - val_loss: 0.7081 - val_acc: 0.7512\n",
            "Epoch 23/25\n",
            "781/781 [==============================] - 42s 54ms/step - loss: 0.8181 - acc: 0.7117 - val_loss: 0.7001 - val_acc: 0.7526\n",
            "Epoch 24/25\n",
            "781/781 [==============================] - 42s 54ms/step - loss: 0.8037 - acc: 0.7155 - val_loss: 0.6902 - val_acc: 0.7563\n",
            "Epoch 25/25\n",
            "781/781 [==============================] - 41s 52ms/step - loss: 0.7971 - acc: 0.7180 - val_loss: 0.6936 - val_acc: 0.7560\n",
            "Accuracy: 75.60%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jQ-Qj1r1eLj",
        "colab_type": "text"
      },
      "source": [
        "### 2.2.1 Classifier Accuracy over Training Period (Epochs = 100)\n",
        "\n",
        "Augmenting the data resulted in a decreased accuracy of 3%, from 78.37% to 75.60%. The data augmentation may have acted against training accuracy due to the possibility of over-fitting data with increased degrees of augmentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNmz5YP_plox",
        "colab_type": "code",
        "outputId": "489ff852-0c4f-4545-be21-9b053cfa7b45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "val_acc = history.history['val_acc']\n",
        "num_iterations = []\n",
        "for i in range(1,26):\n",
        "   num_iterations.append(i)\n",
        "\n",
        "# plotting accuracy vs. number of epochs\n",
        "pyplot.xlabel(\"Number of Epochs\")\n",
        "pyplot.ylabel(\"Accuracy\")\n",
        "pyplot.plot(num_iterations, val_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5181f000b8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKQhEREJOQSAiEnIKAhGRkFMQiIiE3P8H52wq7Az5P5EAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_b7UgMLS4Wxz",
        "colab_type": "text"
      },
      "source": [
        "### 2.3 Increased Number of Epochs and Data Augmentation\n",
        "In the following code segment, we increase the number of epochs (5) and augment data (but decrease the rotation_range to 15)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_FkPlmN7KNl",
        "colab_type": "code",
        "outputId": "c9e29d52-2bf2-4830-fb75-cf30230399c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# load data, normalize by dividing rgb vals by 255, and one-hot encode\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "\n",
        "# same pattern as previous model, except repeated 3 times with larger feature maps\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "# larger dense layer (512 instead of 10)\n",
        "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# number of epochs and learning rate stays the same, but batch size increases to 64\n",
        "epochs = 50\n",
        "lrate = 0.01\n",
        "decay = lrate/epochs\n",
        "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# augmenting the data\n",
        "data_augmentation = ImageDataGenerator(rotation_range=15, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True,)\n",
        "data_augmentation.fit(X_train)\n",
        " \n",
        "# training the model\n",
        "history = model.fit_generator(data_augmentation.flow(X_train, y_train, batch_size=64),\\\n",
        "                    steps_per_epoch=x_train.shape[0] // 64,epochs=epochs,\\\n",
        "                    verbose=1,validation_data=(x_test,y_test))\n",
        "\n",
        "# accuracy of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_227 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "dropout_180 (Dropout)        (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_228 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_112 (MaxPoolin (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_229 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "dropout_181 (Dropout)        (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_230 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_113 (MaxPoolin (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_231 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "dropout_182 (Dropout)        (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_232 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_114 (MaxPoolin (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_26 (Flatten)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_183 (Dropout)        (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_70 (Dense)             (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dropout_184 (Dropout)        (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_71 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_185 (Dropout)        (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_72 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 2,915,114\n",
            "Trainable params: 2,915,114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 1.9794 - acc: 0.2668 - val_loss: 1.6527 - val_acc: 0.4215\n",
            "Epoch 2/50\n",
            "781/781 [==============================] - 42s 54ms/step - loss: 1.6092 - acc: 0.4111 - val_loss: 1.4378 - val_acc: 0.4776\n",
            "Epoch 3/50\n",
            "781/781 [==============================] - 41s 53ms/step - loss: 1.4502 - acc: 0.4709 - val_loss: 1.3405 - val_acc: 0.5152\n",
            "Epoch 4/50\n",
            "781/781 [==============================] - 41s 53ms/step - loss: 1.3372 - acc: 0.5160 - val_loss: 1.1666 - val_acc: 0.5837\n",
            "Epoch 5/50\n",
            "781/781 [==============================] - 42s 53ms/step - loss: 1.2423 - acc: 0.5490 - val_loss: 1.0628 - val_acc: 0.6221\n",
            "Epoch 6/50\n",
            "781/781 [==============================] - 41s 52ms/step - loss: 1.1712 - acc: 0.5816 - val_loss: 1.0116 - val_acc: 0.6349\n",
            "Epoch 7/50\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 1.0999 - acc: 0.6084 - val_loss: 0.9222 - val_acc: 0.6702\n",
            "Epoch 8/50\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 1.0453 - acc: 0.6269 - val_loss: 0.9120 - val_acc: 0.6738\n",
            "Epoch 9/50\n",
            "781/781 [==============================] - 42s 54ms/step - loss: 0.9952 - acc: 0.6455 - val_loss: 0.8457 - val_acc: 0.7024\n",
            "Epoch 10/50\n",
            "781/781 [==============================] - 42s 53ms/step - loss: 0.9533 - acc: 0.6621 - val_loss: 0.8643 - val_acc: 0.6956\n",
            "Epoch 11/50\n",
            "781/781 [==============================] - 41s 52ms/step - loss: 0.9159 - acc: 0.6743 - val_loss: 0.7696 - val_acc: 0.7316\n",
            "Epoch 12/50\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 0.8858 - acc: 0.6858 - val_loss: 0.7739 - val_acc: 0.7282\n",
            "Epoch 13/50\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.8552 - acc: 0.6987 - val_loss: 0.7221 - val_acc: 0.7435\n",
            "Epoch 14/50\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.8347 - acc: 0.7055 - val_loss: 0.7455 - val_acc: 0.7382\n",
            "Epoch 15/50\n",
            "781/781 [==============================] - 41s 53ms/step - loss: 0.8092 - acc: 0.7146 - val_loss: 0.7022 - val_acc: 0.7611\n",
            "Epoch 16/50\n",
            "781/781 [==============================] - 41s 52ms/step - loss: 0.7903 - acc: 0.7202 - val_loss: 0.6810 - val_acc: 0.7628\n",
            "Epoch 17/50\n",
            "781/781 [==============================] - 41s 53ms/step - loss: 0.7786 - acc: 0.7267 - val_loss: 0.6740 - val_acc: 0.7659\n",
            "Epoch 18/50\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.7561 - acc: 0.7331 - val_loss: 0.6389 - val_acc: 0.7740\n",
            "Epoch 19/50\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.7390 - acc: 0.7395 - val_loss: 0.6325 - val_acc: 0.7820\n",
            "Epoch 20/50\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.7180 - acc: 0.7467 - val_loss: 0.6309 - val_acc: 0.7838\n",
            "Epoch 21/50\n",
            "781/781 [==============================] - 41s 53ms/step - loss: 0.7113 - acc: 0.7480 - val_loss: 0.6284 - val_acc: 0.7813\n",
            "Epoch 22/50\n",
            "781/781 [==============================] - 41s 52ms/step - loss: 0.6952 - acc: 0.7533 - val_loss: 0.6025 - val_acc: 0.7902\n",
            "Epoch 23/50\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 0.6837 - acc: 0.7581 - val_loss: 0.5891 - val_acc: 0.7960\n",
            "Epoch 24/50\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.6708 - acc: 0.7635 - val_loss: 0.6040 - val_acc: 0.7921\n",
            "Epoch 25/50\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.6651 - acc: 0.7667 - val_loss: 0.5896 - val_acc: 0.7992\n",
            "Epoch 26/50\n",
            "781/781 [==============================] - 41s 53ms/step - loss: 0.6561 - acc: 0.7697 - val_loss: 0.5905 - val_acc: 0.7971\n",
            "Epoch 27/50\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 0.6481 - acc: 0.7711 - val_loss: 0.5749 - val_acc: 0.8016\n",
            "Epoch 28/50\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.6340 - acc: 0.7781 - val_loss: 0.5484 - val_acc: 0.8115\n",
            "Epoch 29/50\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.6296 - acc: 0.7780 - val_loss: 0.5637 - val_acc: 0.8063\n",
            "Epoch 30/50\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.6244 - acc: 0.7800 - val_loss: 0.5687 - val_acc: 0.8028\n",
            "Epoch 31/50\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.6142 - acc: 0.7843 - val_loss: 0.5472 - val_acc: 0.8100\n",
            "Epoch 32/50\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.6150 - acc: 0.7841 - val_loss: 0.5410 - val_acc: 0.8152\n",
            "Epoch 33/50\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.5986 - acc: 0.7907 - val_loss: 0.5259 - val_acc: 0.8169\n",
            "Epoch 34/50\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.6017 - acc: 0.7868 - val_loss: 0.5388 - val_acc: 0.8136\n",
            "Epoch 35/50\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.5871 - acc: 0.7941 - val_loss: 0.5328 - val_acc: 0.8174\n",
            "Epoch 36/50\n",
            "781/781 [==============================] - 41s 52ms/step - loss: 0.5818 - acc: 0.7946 - val_loss: 0.5499 - val_acc: 0.8084\n",
            "Epoch 37/50\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 0.5755 - acc: 0.7965 - val_loss: 0.5267 - val_acc: 0.8172\n",
            "Epoch 38/50\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.5753 - acc: 0.7975 - val_loss: 0.5309 - val_acc: 0.8174\n",
            "Epoch 39/50\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.5624 - acc: 0.8030 - val_loss: 0.5358 - val_acc: 0.8170\n",
            "Epoch 40/50\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.5598 - acc: 0.8026 - val_loss: 0.5102 - val_acc: 0.8245\n",
            "Epoch 41/50\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.5544 - acc: 0.8050 - val_loss: 0.5006 - val_acc: 0.8284\n",
            "Epoch 42/50\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.5482 - acc: 0.8063 - val_loss: 0.5129 - val_acc: 0.8269\n",
            "Epoch 43/50\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.5448 - acc: 0.8065 - val_loss: 0.5226 - val_acc: 0.8235\n",
            "Epoch 44/50\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.5410 - acc: 0.8083 - val_loss: 0.5057 - val_acc: 0.8275\n",
            "Epoch 45/50\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.5379 - acc: 0.8101 - val_loss: 0.5148 - val_acc: 0.8264\n",
            "Epoch 46/50\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.5335 - acc: 0.8112 - val_loss: 0.4878 - val_acc: 0.8311\n",
            "Epoch 47/50\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 0.5314 - acc: 0.8133 - val_loss: 0.4867 - val_acc: 0.8332\n",
            "Epoch 48/50\n",
            "781/781 [==============================] - 41s 52ms/step - loss: 0.5256 - acc: 0.8167 - val_loss: 0.4891 - val_acc: 0.8326\n",
            "Epoch 49/50\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.5238 - acc: 0.8158 - val_loss: 0.4819 - val_acc: 0.8371\n",
            "Epoch 50/50\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.5169 - acc: 0.8181 - val_loss: 0.5163 - val_acc: 0.8267\n",
            "Accuracy: 82.67%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpeFCsfcDmAv",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.1 Classifier Accuracy over Training Period (Data Augentation + 50 Epochs)\n",
        "\n",
        "Augmenting the data resulted in an increased accuracy of 5%, from 78.37% to 83.31%. Given the results from the original data augmentation, it seems that reducing the rotation_range may have increased accuracy by reducing overfitting -- combined with an increased number of epochs (as determined by a suitable range from section 2.1, where an early-stopping step was determined to be within the range of 30-60). It seems that the data augmentation performed did not have demonstrable improvements in accuracy; decreasing the range may have reduced overfitting, but in combination with an increased number of epochs, it can be reasonably said that augmenting the data has a positive increase in accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_H0lAzaEjeX",
        "colab_type": "code",
        "outputId": "bf851446-62e9-4e93-a4ab-3ba0b11c139a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "val_acc = history.history['val_acc']\n",
        "num_iterations = []\n",
        "for i in range(1,51):\n",
        "   num_iterations.append(i)\n",
        "\n",
        "# plotting accuracy vs. number of epochs\n",
        "pyplot.xlabel(\"Number of Epochs\")\n",
        "pyplot.ylabel(\"Accuracy\")\n",
        "pyplot.plot(num_iterations, val_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f51138c6780>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOCUCEZEYp0QgIhLjlAhERGLc/we2VA4LXjBY9gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6Tbhoa2Fa-H",
        "colab_type": "text"
      },
      "source": [
        "### 2.4 Conclusion\n",
        "\n",
        "From our results, it seems that increasing the number of epochs has a positive increase in accuracy, but data augmentation must be done carefully -- that is to say, feature transformation should be chosen carefully and managed in order to reduce the risk of overfitting data. The best results came from combining the two approaches of increasing the number of epochs (to an early stop, determined by previous experiments) and using data augmentation to increase the amount of training data. In further continuations of this task, it would be interesting to see the results of using a deeper layered network, as well as introducing normalization before ouputting to the next layer."
      ]
    }
  ]
}